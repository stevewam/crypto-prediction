{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston\n",
    "import sklearn.model_selection\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker.predictor import csv_serializer\n",
    "\n",
    "session = sagemaker.Session()\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"./data/processed_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be experimenting with the following algorithms for the model:\n",
    "1. XGBoost\n",
    "2. Simple Custom Neural Net\n",
    "3. Long Short Term Memory Networks\n",
    "\n",
    "Before I work with these models, I will start with the benchmark model first which is based on Simple Moving Average model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Simple Moving Average (SMA)</h2>\n",
    "\n",
    "In Simple Moving Average, the predicted next price is equal to the average of the last $w$ data points. In addition to creating this model, I will be creating the function to implement the trading strategy in this section as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sma_prices(data_df, w):\n",
    "    # Since predicted price is the average of the last w price, we can use create_features function\n",
    "    features_df = source.create_features(data_df, w)\n",
    "    features_df.index = pd.to_datetime(features_df['time'])\n",
    "    \n",
    "    sma_features_df = features_df[['sym', 'price_4_last', 'price_1_mean', 'target_price']]\n",
    "    sma_features_df.columns = ['sym', 'previous_price', 'predicted_price', 'actual_price']\n",
    "    sma_features_df['expected_roi'] = sma_features_df['predicted_price']/sma_features_df['previous_price'] - 1\n",
    "    sma_features_df['actual_roi'] = sma_features_df['actual_price']/sma_features_df['previous_price'] - 1\n",
    "    \n",
    "    return sma_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sma_prices_df = predict_sma_prices(data_df, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sym</th>\n",
       "      <th>previous_price</th>\n",
       "      <th>predicted_price</th>\n",
       "      <th>actual_price</th>\n",
       "      <th>expected_roi</th>\n",
       "      <th>actual_roi</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-30</th>\n",
       "      <td>$$$</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.258519</td>\n",
       "      <td>-0.037037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-31</th>\n",
       "      <td>$$$</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.306154</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-01</th>\n",
       "      <td>$$$</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.293077</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-02</th>\n",
       "      <td>$$$</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.296154</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-03</th>\n",
       "      <td>$$$</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.299231</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sym  previous_price  predicted_price  actual_price  expected_roi  \\\n",
       "time                                                                           \n",
       "2016-01-30  $$$        0.000027         0.000034      0.000026      0.258519   \n",
       "2016-01-31  $$$        0.000026         0.000034      0.000026      0.306154   \n",
       "2016-02-01  $$$        0.000026         0.000034      0.000026      0.293077   \n",
       "2016-02-02  $$$        0.000026         0.000034      0.000026      0.296154   \n",
       "2016-02-03  $$$        0.000026         0.000034      0.000026      0.299231   \n",
       "\n",
       "            actual_roi  \n",
       "time                    \n",
       "2016-01-30   -0.037037  \n",
       "2016-01-31    0.000000  \n",
       "2016-02-01    0.000000  \n",
       "2016-02-02    0.000000  \n",
       "2016-02-03    0.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sma_prices_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the predicted price for a given time period, we can build a portfolio at each time step so that we can have an idea how much profit can be generated by using the SMA prediction model. The strategy employed to build the portfolio will be standardized accross all the different prediction model we will explore later as well.\n",
    "\n",
    "The strategy will be to invest in the top $n$ coins with the highest expected ROI and then sell it the following day. To simplify the calculation, we will be ignoring the transaction cost. As the algorithm continues to trade, it will re-evaluate the best value of $n$ for a given time period to maximize the Sharpe ratio.\n",
    "\n",
    "We will be trading for 1 year from April 24, 2016 and April 24, 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sharpe_ratio(array):\n",
    "    return np.mean(array)/np.std(array)\n",
    "\n",
    "def calculate_next_sharpe_ratio(roi_history, new_value):\n",
    "    new_hist = roi_history + [new_value]\n",
    "    return np.mean(new_hist)/np.std(new_hist)\n",
    "\n",
    "def update_mean(mean, t, new_value):\n",
    "    if t == 0:\n",
    "        return new_value\n",
    "    else:\n",
    "        return (mean * (t - 1) + new_value) / t\n",
    "\n",
    "def update_std(std, mean, new_mean, t, new_value):\n",
    "    if t == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.sqrt((std ** 2 * (t - 1) + (new_value - new_mean) * (new_value - mean)) / t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2018-04-12 00:00:00; Total: 6437851911952914007319257872467999800316671803338861425377750284822773363405751094165316087615183187351916362027488226062559955919044608.00; Day Change: 947072580399698926753895054354188840028677523177118646270814884999241665832782055024301289775064822988532778762501977971920940667240448.00; n: 10, Cum. Returns: 64378519119529145318387643588713070741752536164506483985992394532587994071334328914843643097860508464986287470554852364803917628833792.00%, Sharpe: inf\n"
     ]
    }
   ],
   "source": [
    "initial_value = 10000\n",
    "total_value = initial_value\n",
    "sharpe_ratio = None\n",
    "mean_roi = 0\n",
    "std_roi = 0\n",
    "initial_n = 10\n",
    "t = 1\n",
    "percent_returns = 0\n",
    "\n",
    "dates = list(set([time for time in sma_prices_df.index if time > pd.Timestamp('2016-04-24')]))\n",
    "dates.sort()\n",
    "\n",
    "for date in dates:\n",
    "    \n",
    "    coins_stats_df = sma_prices_df.loc[date,:]\n",
    "    coins_stats_df = coins_stats_df.sort_values(by='expected_roi', ascending=False)\n",
    "    \n",
    "    if t != 1:\n",
    "        sharpe_select_df = []\n",
    "        \n",
    "        coins_stats_df['avg_expected_roi'] = coins_stats_df['expected_roi'].expanding().mean()\n",
    "        coins_stats_df['new_mean'] = coins_stats_df['avg_expected_roi'].apply(lambda x: update_mean(mean_roi, t, x))\n",
    "        coins_stats_df['new_std'] = coins_stats_df.apply(lambda row: update_std(std_roi, mean_roi, row['new_mean'], t, row['avg_expected_roi']), axis=1)\n",
    "        coins_stats_df['sharpe_ratio'] = coins_stats_df['new_mean']/coins_stats_df['new_std']\n",
    "        coins_stats_df['n'] = np.arange(start=1, stop=(len(coins_stats_df)+1))\n",
    "        \n",
    "        n = coins_stats_df[coins_stats_df['sharpe_ratio']==coins_stats_df['sharpe_ratio'].max()]['n'].values[0]\n",
    "        \n",
    "    else:\n",
    "        n = initial_n\n",
    "        \n",
    "    n_index = n - 1        \n",
    "    day_return = sum(coins_stats_df.iloc[:n,:]['actual_roi'] * total_value / n)\n",
    "    day_roi = day_return/total_value\n",
    "    total_value += day_return\n",
    "    percent_returns = (total_value/initial_value - 1 ) * 100\n",
    "    \n",
    "    prev_mean_roi = mean_roi\n",
    "    mean_roi = update_mean(prev_mean_roi, t, day_roi)\n",
    "    std_roi = update_std(std_roi, prev_mean_roi, mean_roi, t, day_roi)\n",
    "    sharpe_ratio = mean_roi/std_roi\n",
    "\n",
    "print('Date: {}; Total: {:.2f}; Day Change: {:.2f}; n: {}, Cum. Returns: {:.2f}%, Sharpe: {:.2f}'.format(date, total_value, day_return, n, percent_returns, sharpe_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bos_pd = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "Y_bos_pd = pd.DataFrame(boston.target)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(X_bos_pd, Y_bos_pd, test_size=0.33)\n",
    "X_train, X_val, Y_train, Y_val = sklearn.model_selection.train_test_split(X_train, Y_train, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([Y_val, X_val], axis=1).to_csv(os.path.join(data_dir, 'validation.csv'), header=False, index=False)\n",
    "pd.concat([Y_train, X_train], axis=1).to_csv(os.path.join(data_dir, 'train.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'boston-xgboost-deploy-hl'\n",
    "\n",
    "val_location = session.upload_data(os.path.join(data_dir, 'validation.csv'), key_prefix=prefix)\n",
    "train_location = session.upload_data(os.path.join(data_dir, 'train.csv'), key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = get_image_uri(session.boto_region_name, 'xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = sagemaker.estimator.Estimator(container, # The name of the training container\n",
    "                                    role,      # The IAM role to use (our current role in this case)\n",
    "                                    train_instance_count=1, # The number of instances to use for training\n",
    "                                    train_instance_type='ml.m4.xlarge', # The type of instance ot use for training\n",
    "                                    output_path='s3://{}/{}/output'.format(session.default_bucket(), prefix), # Where to save the output (the model artifacts)\n",
    "                                    sagemaker_session=session) # The current SageMaker session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        objective='reg:linear',\n",
    "                        early_stopping_rounds=10,\n",
    "                        num_round=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Performance\n",
    "xgb_transformer = xgb.transformer(instance_count = 1, instance_type = 'ml.m4.xlarge')\n",
    "xgb_transformer.transform(test_location, content_type='text/csv', split_type='Line')\n",
    "xgb_transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive $xgb_transformer.output_path $data_dir\n",
    "Y_pred = pd.read_csv(os.path.join(data_dir, 'test.csv.out'), header=None)\n",
    "plt.scatter(Y_test, Y_pred)\n",
    "plt.xlabel(\"Median Price\")\n",
    "plt.ylabel(\"Predicted Price\")\n",
    "plt.title(\"Median Price vs Predicted Price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deployment\n",
    "xgb_predictor = xgb.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')\n",
    "xgb_predictor.content_type = 'text/csv'\n",
    "xgb_predictor.serializer = csv_serializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = xgb_predictor.predict(X_test.values).decode('utf-8')\n",
    "Y_pred = np.fromstring(Y_pred, sep=',')\n",
    "\n",
    "xgb_predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
